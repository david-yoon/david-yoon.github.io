---
layout: page
title: "David Seunghyun Yoon"
---

<img src="{{ site.baseurl }}/assets/profile/img" align="right" title="Profile Picture" class="profile">
<!--<font size="5"><strong>David Seunghyun Yoon </strong></font> <br>-->
<br>
<font size="3">
	<strong>PhD</strong><br>
	Dept. of Electrical & Computer Engineering <br>
	Seoul National Unviersity<br><br>
    <!--
    <strong>NLP Research Scientist</strong><br>
	Adobe Research (San Jose, CA, US)
    -->
</font>



<br>
<br style="line-height:1.0em"> <a href="mailto:mysmilesh@gmail.com">mysmilesh@gmail.com</a>
<br>[<a href="{{ site.baseurl }}/assets/cv.pdf">CV</a>]&nbsp;
    [<a href="https://scholar.google.co.kr/citations?user=UpymOMwAAAAJ">Google Scholar</a>]&nbsp;
    [<a href="http://github.com/david-yoon/">GitHub</a>]&nbsp;
    [<a href="http://www.linkedin.com/in/david-s-yoon/">LinkedIn</a>]&nbsp;
    [<a href="http://twitter.com/david_s_yoon/">twitter</a>]
<br>

<br><br>
<hr>

<!--
<p>I'm a Ph.D. candidate at <a href="http://milab.snu.ac.kr">Machine Intelligence Lab.</a> at <a href="http://www.snu.ac.kr">Seoul National University</a>. I am advised by Prof. <a href="http://milab.snu.ac.kr/kjung/index.html" title="Kyomin Jung">Kyomin Jung</a> at Dept. of Electrical and Computer Engineering. Before coming to SNU, I was a staff software engineer at Samsung artificial intelligence (AI) research center.</p>

<p>I'm a Ph.D. candidate at Dept. of Electrical and Computer Engineering, Seoul National University</a>.
My  Ph.D. advisor is Prof. <a href="http://milab.snu.ac.kr/kjung/index.html" title="Kyomin Jung">Kyomin Jung</a>. Before coming to SNU, I was a staff software engineer at Samsung Research AI Center.</p>

<p>My research interests are in the areas of machine learning and natural language processing (NLP). In particular, I am interested in the question-answering system and dialogue model.</p>
-->

<p>
    My research interests are in the areas of <strong>machine learning</strong> and <strong>natural language processing (NLP)</strong>. I am particularly interested in understanding long texts for question answering systems and learning language representation for NLP tasks. Further interests lie in applying and integrating NLP research with other disciplines to tackle practical issues; understanding multimodal information (i.e., text, audio, and visual) and NLP for social good.

<p>My  Ph.D. advisor is <a href="http://milab.snu.ac.kr/kjung/index.html" title="Kyomin Jung">Dr. Kyomin Jung</a>, Dept. of Electrical and Computer Engineering, Seoul National University. Before coming to SNU, I was a staff software engineer at Samsung Research AI Center.
    
I have published studies at NLP, AI, or signal processing conferences, such as <strong>ACL</strong>, <strong>NAACL</strong>, <strong>AAAI</strong>, <strong>CIKM</strong>, and <strong>ICASSP</strong>.
</p>

<!--<p><strong>Keywords:</strong> NLP, Machine Learning, Artificial Intelligence</p>-->

<hr>


<h3>News</h3>

<ul style="line-height:1.4em">
  <font size="2">
  <li>
	Aug. 2020 :
    I am awarded the <strong>Distinguished Dissertation Award</strong>, Dept. ECE, Seoul National University.
  </li> 
  <li>
	Jul. 2020 :
	Our paper (multimodal speech emotion) is accepted to <a href="http://www.interspeech2020.org/">INTERSPEECH 2020</a>.
  </li> 
  <li>
	Jul. 2020 : I gave a talk at KAIST/IBS, "Understanding Long Texts for Question Answering System Using DNN"
  </li>  
  <li>
	Jun. 2020 :
      <strong>I defend my PhD!.</strong>
  </li>  
  <li>
	May. 2020 :
	One paper (signal compression) is accepted for publication in <a href="https://www.springer.com/journal/11227?gclid=EAIaIQobChMIrJqOzti96QIVBhdgCh1UVAn_EAAYASAAEgLwp_D_BwE">The Journal of Supercomputing 2020</a>.
  </li>  
  <li>
	Apr. 2020 :
	Our paper (language representation) is accepted to <a href="https://acl2020.org/">ACL 2020</a>.
  </li>  
  <li>
	Feb. 2020 :
	I am awarded the <a href="https://buildyourfuture.withgoogle.com/scholarships/google-travel-and-conference-grants/#!?detail-content-tabby_activeEl=overview">Google Conference and Travel Scholarships</a> for the ICASSP-20 paper.
  </li>
  <li>
	Feb. 2020 :
	One paper (QA) is accepted to <a href="https://lrec2020.lrec-conf.org/">LREC 2020</a>.
  </li>
  <li>
	Jan. 2020 :
	Our paper (adverse drug reaction) is accepted to <a href="https://pakdd2020.org/">PAKDD 2020</a> as <strong>oral presentation</strong>.
  </li>  
  <li>
	Jan. 2020 :
	One paper (multimodal speech emotion) is accepted to <a href="https://2020.ieeeicassp.org/">IEEE ICASSP 2020</a> as <strong>oral presentation</strong>.
  </li>  
<!--
  <li>
	Dec. 2019 :
	One patent (dialogue) is issued in Korea (10-2059015).
  </li>
    <li>
	Dec. 2019 :
	Our paper (multimodal dialogue) is accepted to <a href="https://sites.google.com/dstc.community/dstc8/">AAAI 2020 workshop on DSTC8</a>.
  </li>
  <li>
	Nov. 2019 :
	Our paper (fakenews detection) is accepted as a book chapter on <a href="https://www.springer.com/gp/book/9783030426989">FNDM</a>, Springer 2020
  </li>
  <li>
	Aug. 2019 :
	One paper (QA) is accepted to <a href="http://www.cikm2019.net/">ACM CIKM 2019</a>.
  </li>
  <li>
	Jul. 2019 :
	I gave a talk at <a href="https://www.nvidia.com/ko-kr/ai-conference/">NVIDIA AI Conference</a>, 
		"Research in Natural Language Processing"
  </li>
  <li>
	Jun. 2019 :
	Our paper is accepted to <a href="http://www.acl2019.org/EN/workshops.xhtml/">ACL 2019 workshop on BioNLP.</a>
  </li>
  <li>
	May. 2019 :
	I am awarded the <a href="https://buildyourfuture.withgoogle.com/scholarships/google-travel-and-conference-grants/#!?detail-content-tabby_activeEl=overview">Google Conference and Travel Scholarships</a> for the ICASSP-19 paper.
  </li>
  <li>
	Feb. 2019 :
	One paper (multimodal speech emotion) is accepted to <a href="https://2019.ieeeicassp.org/">IEEE ICASSP 2019</a> as <strong>oral presentation</strong>.
  	</li>
	<li>
	Dec. 2018 :
	One paper is (feature compression) accepted to <a href="http://www.bigcomputing.org/">IEEE BigComp 2019.</a>
  </li>
	<li>
	Nov. 2018 :
	One paper is accepted (incongruent news article) to <a href="https://aaai.org/Conferences/AAAI-19/">AAAI 2019</a> as <strong>oral presentation</strong>.
  </li>
  <li>
	Sep. 2018 :
	One paper (multimodal speech emotion) is accepted to <a href="http://www.slt2018.org/">IEEE SLT 2018.</a>
  </li>
  <li>
	Aug. 2018 :
	One paper (abusive language) is accepted to <a href="http://emnlp2018.org/program/workshops/">EMNLP 2018 workshop on ALW2.</a>
  </li>
  <li>
	Aug. 2018 : 
	I gave a talk at <a href="https://www.navercorp.com/en/">Naver</a>, 
		<a href="https://youtu.be/ir-AqEaCn7Y">"QA-pair ranking algorithm and its applications"</a>
  </li>
  <li>
	Jul. 2018 : 
	I gave a talk at <a href="https://www.youtube.com/playlist?list=PLpnJjnJBNxUMFwlC0Wjm51FJZDXbyP4ad">Paper Day 2018</a>, 
		<a href="https://www.facebook.com/groups/PyTorchKR/">PyTorch KR</a>
  </li>
  <li>
	Jul. 2018 : 
	I gave a talk at <a href="https://www.fastcampus.co.kr/data_camp_lab/">Fast campus</a>, "Advancement of the Neural Dialogue Model"
  </li>
  <li>
	Jun. 2018 :
	One paper (QA) is accepted to <a href="https://naacl2018.wordpress.com/2018/03/02/list-of-accepted-papers/">NAACL 2018.</a>
  </li>
  <li>
	Jan. 2018 :
	One paper is accepted to <a href="http://www.bigcomputing.org/">IEEE BigComp 2018.</a>
  </li>
-->
</ul>

<hr>

<h3>Academic Activities</h3>
<ul style="line-height:1.4em">
  <li>
	<strong><font color=darkblue>Service: </font></strong> <br>
	<strong>Program Committee</strong>, NAACL (2019), ACL (2020), EMNLP (2019, 2020), AACL (2020), EACL (2021) <br>
    <strong>Program Committee</strong>, AAAI (2020), WWW (2021), INTERSPEECH (2019) <br>
    <strong>Journal Reviewer</strong>, Information Processing and Management, 2020 <br>
    <strong>Journal Reviewer</strong>, IEEE Signal Processing Letters, 2020 <br>
    <br>
  </li>
  <li>
	<strong><font color=darkblue>Invited Talks: </font></strong> <br>
    Understanding Long Texts for Question Answering System Using DNN, <strong>KAIST/IBS</strong>, Jul. 2020<br>
    Question Answering System for Long Text, <strong>Adobe Research</strong> (San Jose, CA, US), Dec. 2019<br>
    Question Answering System and Multimodal Speech Emotion Recognition, <strong>DEEPEST</strong>, Aug. 2019<br>
	Research in Natural Language Processing, 
	<a href="https://www.nvidia.com/ko-kr/ai-conference/"><strong>NVIDIA AI Conference</strong></a>, Jul. 2019<br>
	Question Answering for Short Answer, <strong>Adobe Research</strong> (San Jose, CA, US), Dec. 2018<br>
	QA-pair ranking algorithm and its applications, <strong>NAVER</strong>, Aug. 2018<br>
    Learning to Rank Question-Answer Pairs, <strong>PyTorch KR</strong>, Jun. 2018<br>
	Advancement of the Neural Dialogue Model, 
	<a href="https://www.fastcampus.co.kr/data_camp_lab/"><strong>Fast campus</strong></a>, 
	Jul. 2018 <br>
	<br>
  </li>
  <li><font size="2">
	<strong><font color=darkblue>Teaching Assistant: </font></strong> <br>
	Programming Methodology, Seoul National University, Spring 2018 <br>
	Machine Learning, Seoul National University, Fall 2015 <br>
	Lab. Sentiment Analysis, BigCamp (Big Data Academy), Big Data Institute, 2016-2019 <br>
	<br>
  </li>
  </font>
</ul>

<hr>

<h3>Professional Experiences</h3>
<ul style="line-height:1.4em">
	<li><font size="2">
	<strong><font color=darkblue>NLP Research Scientist: </font></strong>
	Adobe Research (San Jose, CA, US),
	2020-present
  </li>
  <li><font size="2">
	<strong><font color=darkblue>Research Scientist Intern: </font></strong>
	Adobe Research (San Jose, CA, US),
	Fall 2018 
  </li>
  <li>
	<strong><font color=darkblue>Staff Engineer: </font></strong>
	Samsung Research AI Center (Seoul, KR),
	2006-2017
  </li>
  <li>
	<strong><font color=darkblue>Representative of employees: </font></strong>
	Samsung Electronics (Seoul, KR),
	2012-2014
  </li>
  <li>
	<strong><font color=darkblue>Trainer of Global New Employee Course: </font></strong>
	Samsung Electronics (Seoul, KR),
	Spring 2011 
  </li></font></ul>
</ol>

<hr>

<!--<h3>Publications</h3>-->
<h3>International Conference Proceedings</h3>
*denotes equal contribution.<br>

<ol style="line-height:1.4em" reversed>
  <font size="2">
  <li >
	<strong>Multimodal Speech Emotion Recognition using Cross Attention with Aligned Audio and Text</strong>
  	<br><i>Y Lee, <u>S Yoon</u>, K Jung</i>
	<br><a href="http://www.interspeech2020.org/">INTERSPEECH 2020</a>
    <p>
  </li> 
  <li >
	<strong>Fast and Accurate Deep Bidirectional Language Representations for Unsupervised Learning</strong>
      [<a href="https://www.aclweb.org/anthology/2020.acl-main.76.pdf">paper</a>]
      [<a href="https://github.com/joongbo/tta">code</a>]
    <br>(<font color=orange>acceptance rate: 25.2%</font>)
  	<br><i>J Shin, Y Lee, <u>S Yoon</u>, K Jung</i>
	<br><a href="https://acl2020.org/">ACL 2020</a>
    <p>
  </li> 
  <li >
	<strong>Propagate-Selector: Detecting Supporting Sentences for Question Answering via Graph Neural Networks</strong>
	[<a href="https://www.aclweb.org/anthology/2020.lrec-1.664">paper</a>]
    [<a href="https://github.com/david-yoon/propagate-selector">code</a>]
  	<br><i><u>S Yoon</u>, F Dernoncourt, DS Kim, T Bui, K Jung</i>
	<br><a href="https://lrec2020.lrec-conf.org/">LREC 2020</a>
    <p>
  </li>
  <li >
	<strong>Drug-disease Graph: Predicting Adverse Drug Reaction Signals via Graph Neural Network with Clinical Data</strong>
      [<a href="https://arxiv.org/pdf/2004.00407.pdf">paper</a>]
      [<a href="https://pakdd2020.org/download/conference_paper_slides/main-851.pdf">slide</a>]
  	<br>(<font color=orange>oral presentation, accpetance rate: 21%</font>)
    <br><i>H Kwak, M Lee, <u>S Yoon</u>, J Chang, S Park, K Jung</i>
	<br><a href="https://pakdd2020.org/">PAKDD 2020</a>
    <p>
  </li>
  <li >
	<strong>Attentive Modality Hopping Mechanism for Speech Emotion Recognition</strong>
      [<a href="https://arxiv.org/pdf/1912.00846.pdf">paper</a>]
      [<a href="https://github.com/david-yoon/attentive-modality-hopping-for-SER">code</a>]
      [<a href="https://www.slideshare.net/DavidSeunghyunYoon/slide-attentive-modality-hopping-mechanism-for-speech-emotion-recognition">slide</a>]
	<br>(<font color=orange>oral presentation</font>)
    <br><i><u>S Yoon</u>, S Dey, H Lee, K Jung</i>
	<br><a href="https://2020.ieeeicassp.org/">IEEE ICASSP 2020</a>
    <p>
  </li>
  <li >
	<strong>A Compare-Aggregate Model with Latent Clustering for Answer Selection</strong>
	[<a href="https://arxiv.org/pdf/1905.12897.pdf">paper</a>]
  [<a href="https://www.slideshare.net/DavidSeunghyunYoon/slide-a-compareaggregate-model-with-latent-clustering-for-answer-selection">slide</a>]
  [<a href="https://www.slideshare.net/DavidSeunghyunYoon/poster-a-compareaggregate-model-with-latent-clustering-for-answer-selection">poster</a>]
  <br>(<font color=orange>oral presentation, accpetance rate: 21.2%</font>)
	<br><i><u>S Yoon</u>, F Dernoncourt, DS Kim, T Bui, K Jung</i>
	<br><a href="http://www.cikm2019.net/">CIKM 2019</a>
    <p>
  </li>
  <li >
	<strong>Speech Emotion Recognition Using Multi-hop Attention Mechanism</strong>
	[<a href="https://arxiv.org/pdf/1904.10788.pdf">paper</a>]
    [<a href="https://sigport.org/documents/speech-emotion-recognition-using-multi-hop-attention-mechanism">slide</a>]
	<br>(<font color=orange>oral presentation</font>)
	<br><i><u>S Yoon</u>, S Byun, S Dey, K Jung</i>
	<br><a href="https://2019.ieeeicassp.org/">IEEE ICASSP 2019</a>
    <p>
  </li>
  <li >
	<strong>Neural Networks for Compressing and Classifying Speaker-Independent Paralinguistic Signals</strong>
	[<a href="http://milab.snu.ac.kr/pub/BigComp2019Byun.pdf">paper</a>]
	<br><i>S Byun, <u>S Yoon</u>, K Jung</i>
	<br><a href="http://www.bigcomputing.org/">IEEE BigComp 2019</a>
    <p>
  </li>
	<li >
	<strong>Detecting Incongruity Between News Headline and Body Text via a Deep Hierarchical Encoder</strong>
	[<a href="https://wvvw.aaai.org/ojs/index.php/AAAI/article/view/3756/3634">paper</a>]
	[<a href="https://github.com/david-yoon/detecting-incongruity">code</a>]
    [<a href="https://www.slideshare.net/DavidSeunghyunYoon/detecting-incongruity-between-news-headline-and-body-text-via-a-deep-hierarchical-encoder">slide</a>]
    [<a href="https://www.slideshare.net/DavidSeunghyunYoon/poster-detecting-incongruity-between-news-headline-and-body-text-via-a-deep-hierarchical-encoder">poster</a>]
  <br>(<font color=orange>oral presentation, accpetance rate: 16.2%</font>)
	<br><i><u>S Yoon</u><sup>*</sup>, K Park<sup>*</sup>, J Shin, H Lim, S Won, M Cha, K Jung</i>
	<br><a href="https://aaai.org/Conferences/AAAI-19/">AAAI 2019</a>
    <p>
  </li>
  <li >
	<strong>Learning to Rank Question-Answer Pairs using Hierarchical Recurrent Encoder with Latent Topic Clustering</strong>
	[<a href="https://www.aclweb.org/anthology/N18-1142.pdf">paper</a>] 
	[<a href="https://github.com/david-yoon/QA_HRDE_LTC">code</a>]
	[<a href="https://www.slideshare.net/DavidSeunghyunYoon/learning-to-rank-questionanswer-pairs-using-hierarchical-recurrent-encoder-with-latent-topic-clustering">poster</a>]
  	[<a href="https://youtu.be/k3rAEM91wfM?list=PLpnJjnJBNxUMFwlC0Wjm51FJZDXbyP4ad">video_kor</a>]
  	<br>(<font color=orange>acceptance rate: 31%</font>)
	<br><i><u>S Yoon</u>, J Shin, K Jung</i>
	<br><a href="http://naacl2018.org/">NAACL HLT 2018</a>
    <p>
  </li>
  <li>
	<strong>Contextual-CNN: A Novel Architecture Capturing Unified Meaning for Sentence Classification</strong>	
	[<a href="http://milab.snu.ac.kr/pub/BigComp2018.pdf">paper</a>]	
	<br><i>J Shin, Y Kim, <u>S Yoon</u>, K Jung</i>
	<br><a href="http://www.bigcomputing.org/">IEEE BigComp 2018</a>
    <p>
  </li>
  <li>
	<strong>Synonym Discovery with Etymology-based Word Embeddings</strong></a>	
	[<a href="https://arxiv.org/pdf/1709.10445.pdf">paper</a>]	
	<br><i><u>S Yoon</u>, P Estrada, K Jung</i>
	<br><a href="http://www.ele.uri.edu/ieee-ssci2017/">IEEE SSCI 2017</a>
    <p>
  </li>
  <li>
	<strong>Automatic Question Answering System for Consumer Product</strong>	
	[<a href="http://milab.snu.ac.kr/pub/IntelliSys2016Yoon.pdf">paper</a>]	
	<br><i><u>S Yoon</u>, M Sundar, A Gupta, K Jung</i>
	<br><a href=http://saiconference.com/Conferences/IntelliSys2016">IntelliSys 2016</a>
    <p>
  </li>
  <li>
	<strong>Mining the Minds of Customers from Online Chat Logs</strong>
	[<a href="https://arxiv.org/abs/1510.01801">paper</a>]
	<br>(<font color=orange>accpetance rate: 21%</font>)
	<br><i>K Park, J Kim, J Park, M Cha, J Nam, <u>S Yoon</u>, E Rhim</i>
	<br><a href="http://www.cikm-2015.org/">CIKM 2015</a>
    <p>
  </li>
  <li>
	<strong>Media clips: Implementation of an intuitive media linker</strong>	
	[<a href="{{ site.baseurl }}/assets/paper/MediaClip_BMSB2011.pdf">paper</a>]	
	<br><i><u>S Yoon</u>, K Lee, H Shin</i>
	<br><a href="https://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=5945017">IEEE BMSB 2011</a>
    <p>
  </li>
  </font>
  </ol>  


<hr>
<h3>Journal Publications and Book</h3>
<ol style="line-height:1.4em" reversed>
  <font size="2">
  <li >
	<strong>Comparative Studies on Machine Learning for Paralinguistic Signal Compression and Classification</strong>
    [<a href="https://link.springer.com/content/pdf/10.1007/s11227-020-03346-3.pdf">paper</a>]        
   	<br>(<font color=orange>SCI, IF=2.157</font>)
    <br><i>S Byun<sup>*</sup>, <u>S Yoon</u><sup>*</sup>, K Jung</i>
	<br><a href="https://www.springer.com/journal/11227/?gclid=EAIaIQobChMIrJqOzti96QIVBhdgCh1UVAn_EAAYASAAEgLwp_D_BwE/">Journal of Supercomputing 2020</a>
    <p>
  </li> 
  <li >
	<strong>BaitWatcher: A lightweight web interface for the detection of incongruent news headlines</strong>
    [<a href="https://arxiv.org/pdf/2003.11459.pdf">paper</a>]
    [<a href="https://www.springer.com/gp/book/9783030426989">book</a>]
  	<br><i>K Park, T Kim, <u>S Yoon</u>, M Cha, K Jung</i>
	<br>Disinformation, Misinformation, and Fake News in Social Media-Emerging Research Challenges and Opportunities, <a href="https://www.springer.com/gp/book/9783030426989">Springer 2020</a>
    <p>
  </li>
  <li>
	<strong>Domain Question Answering System</strong>
	<br><i><u>S Yoon</u>, E Rhim, D Kim</i>
	<br>KIISE Transactions on Computing Practices 2015
    <p>
  </li>
  </font>
  </ol>  



<hr>
<h3>Peer Reviewed Workshops</h3>
<ol style="line-height:1.4em" reversed>
  <font size="2">
  <li >
	<strong>DSTC8-AVSD: Multimodal Semantic Transformer Network with Retrieval Style Word Generator</strong>
	[<a href="https://arxiv.org/pdf/2004.08299.pdf">paper</a>]
	<br><i>H Lee, <u>S Yoon</u>, F Dernoncourt, DS Kim, T Bui, K Jung</i>
  <br><a href="https://aaai.org/Conferences/AAAI-20/ws20workshops/#ws09">AAAI 2020 (Workshop on DSTC8)</a>
  <p>
  </li>
  <li >
	<strong>Surf at MEDIQA 2019: Improving Performance of Natural Language Inference in the Clinical Domain by Adopting Pre-trained Language Model</strong>
  [<a href="https://www.aclweb.org/anthology/W19-5043.pdf">paper</a>]
  [<a href="https://www.slideshare.net/jiinnam1/2019-acl-bionlpnlisurfposter">poster</a>]	
	<br><i>J Nam, <u>S Yoon</u>, K Jung</i>
	<br><a href="https://aclweb.org/aclwiki/BioNLP_Workshop">ACL 2019 (Workshop on BioNLP)</a>
    <p>
  </li>
  <li >
	<strong>Multimodal Speech Emotion Recognition using Audio and Text</strong>
	[<a href="https://arxiv.org/pdf/1810.04635.pdf">paper</a>]
    [<a href="https://github.com/david-yoon/multimodal-speech-emotion">code</a>]
    [<a href="https://www.slideshare.net/DavidSeunghyunYoon/multimodal-speech-emotion-recognition-using-audio-and-text">poster</a>]
	<br><i><u>S Yoon</u>, S Byun, K Jung</i>
	<br><a href="http://www.slt2018.org/">IEEE SLT 2018</a>
    <p>
  </li>
  <li >
	<strong>Comparative Studies of Detecting Abusive Language on Twitter</strong>	
	[<a href="https://www.aclweb.org/anthology/W18-5113.pdf">paper</a>]
 	[<a href="https://github.com/younggns/comparative-abusive-lang">code</a>]
	&nbsp
	<br><i>Y Lee<sup>*</sup>, <u>S Yoon</u><sup>*</sup>, K Jung</i>
	<br><a href="https://sites.google.com/view/alw2018">EMNLP 2018 (Workshop on Abusive Language Online)</a>
    <p>
  </li>
  <li>
	<strong>Efficient Transfer Learning Schemes for Personalized Language Modeling using Recurrent Neural Network</strong>	
	[<a href="http://milab.snu.ac.kr/pub/AAAI2017Yoon.pdf">paper</a>]	
	<br><i><u>S Yoon</u>, H Yun, Y Kim, G Park, K Jung</i>
	<br><a href="http://crowdai.azurewebsites.net/">AAAI 2017 (Workshop)</a>
    <p>
  </li>
  </font>
  </ol>  

<hr>

<h3>Patents</h3>
<font color=lightblue>
<h4>[ International Patents ]</h4>
</font>
<ol reversed style="line-height:1.4em">
  <font size="2">
    <li>
    [<font color=magenta>issued</font>]	
	<strong>Terminal apparatus, server and method of controlling the same</strong>
	[<a href="https://patents.google.com/patent/US10084850B2/en?oq=US+10%2c084%2c850/">link</a>]	
	<br><i>Y Kim, O Kwon, S Kim, H Oh, <u>S Yoon</u>, S Cha, J Lee</i>
	<br>US 10,084,850, CN 201410085759, EP20140154718, Sep. 25, 2018
    <p>
  </li>
  
  <li>
	[<font color=magenta>issued</font>]	
	<strong>Method of recommending application, mobile terminal using the method, and communication system using the method</strong>
	[<a href="https://patents.google.com/patent/US9247376B2/en?oq=US+9%2c247%2c376">link</a>]	
	<br><i>J Nam, M Lee, M Koo, <u>S Yoon</u></i>
	<br>US 9,247,376, Jan. 26, 2016 &nbsp
    <p>
  </li>
  
  <li>
	[<font color=magenta>issued</font>]&nbsp
	<strong>Method and apparatus for displaying photo on screen having any shape</strong>
	[<a href="https://patents.google.com/patent/US9049383B2/en?oq=US+9%2c049%2c383">link</a>]	
	<br><i><u>S Yoon</u>, M Lee</i>
	<br>US 9,049,383, Jun. 2, 2015 &nbsp
	<p>
  </li>
  
  <li>
	[<font color=magenta>issued</font>]&nbsp
	<strong>Method and apparatus for providing information and computer readable storage medium having a program recorded thereon for executing the method</strong>
	[<a href="https://patents.google.com/patent/US8958824B2/en?oq=US+8%2c958%2c824">link</a>]	
	<br><i><u>S Yoon</u>, M Lee, M Koo, J Nam</i>
	<br>US 8,958,824, Feb. 17, 2015 &nbsp
    <p>
  </li>
  
  <li>
	[<font color=magenta>issued</font>]
	<strong>Method and apparatus for fast tracking position by using global positioning system</strong>
	[<a href="https://patents.google.com/patent/US8094070B2/en?oq=US+8%2c094%2c070">link</a>]	
	<br><i><u>S Yoon</u>, S Kim</i>
	<br>US 8,094,070, Jan. 10, 2012 &nbsp
    <p>
  </li>
  
  <li>
	<strong>Method and device for analyzing user's emotion</strong>
    [<a href="https://patentscope.wipo.int/search/en/detail.jsf?docId=WO2016182393">link</a>]	
	<br><i>E Rhim, J Kim, J Nam, <u>S Yoon</u>, K Park, J Park, M Cha</i>
	<br>WO2016182393, May. 13, 2016
    <p>
  </li>
  
  
  
<!-- 
  <li>
	<strong>User terminal device, information providing system, and method for providing information</strong>
	[<a href="https://patents.google.com/patent/US20150106297A1/">link</a>]		
	<br><i>Y Won, <u>S Yoon</u>, O Kwon, M Kim, H Oh, S Lee, S Cha</i>
	<br>US 14/511,506, EP20140185800, Oct. 10, 2014
    <p>
  </li>

  <li>
	<strong>Apparatus and method for searching with consideration user's action</strong>
	[<a href="https://patents.google.com/patent/US20130086055?oq=13%2f631%2c353">link</a>]
	<br><i><u>S Yoon</u>, M Lee, M Koo, J Nam</i>
	<br>US 13/631,353, Sep. 28, 2012
    <p>
  </li>
-->
  
  <li>
	<strong>Apparatus and method for clipping and sharing content at a portable terminal</strong>
	[<a href="https://patents.google.com/patent/US20130080531?oq=13%2f629%2c394">link</a>]
	<br><i><u>S Yoon</u>, M Lee, M Koo, J Nam</i>
	<br>US 13/629,394, CN 201280047213, EP20120837007, PCT/KR1020110097578, Sep. 27, 2012
    <p>
  </li>
  
<!-- 
  <li>
	<strong>Apparatus and method for correcting position information of portable terminal in multi-path zone</strong>
	[<a href="https://patents.google.com/patent/US20130057430?oq=13%2f604528">link</a>]
	<br><i><u>S Yoon</u></i>
	<br>US 13/604,528, Sep. 5, 2012
    <p>
  </li>
  <li>
	<strong>Method and apparatus for connecting devices</strong>
	[<a href="https://patents.google.com/patent/US20120271901?oq=13%2f452%2c766">link</a>]
	<br><i>K Kim, J Lee, W Park, H Shim, Y Park, M Lee, M Koo, <u>S Yoon</u>, J Nam</i>
	<br>US 13/452,766, EP20120162473, PCT/KR1020110037351 , Apr. 20, 2012
    <p>
  </li>
  <li>
	<strong>Method and apparatus for crawling webpages</strong>
	[<a href="https://patents.google.com/patent/US20120102019?oq=13%2f116%2c785">link</a>]
	<br><i><u>S Yoon</u>, S Maeng, J Huh, S Seo, J Kim, J Park</i>
	<br>US 13/116,785, May. 26, 2011
    <p>
  </li>
-->

  </font>
</ol>

<font color=lightblue>
<h4>[ Korean Patents ]</h4>
</font>
<ol reversed style="line-height:1.4em">
  <font size="2">
  
  <li>
    [<font color=magenta>issued</font>]&nbsp
	<strong>Artificial intelligence based dialog system and response control method thereof</strong>
	<br><i>K Jung, <u>S Yoon</u>, J Shin, H Kwak, S Byun</i>
	<br>KR 10-2059015, Dec. 18, 2019
    <p>
  </li>
  
  <li>
	[<font color=magenta>issued</font>]&nbsp
	<strong>Apparatus and method for collecting information of destination in portable terminal</strong>
	<br><i><u>S Yoon</u>, J Nam, M Koo, M Lee</i>
	<br>KR 10-1914632, Oct. 29, 2018
    <p>
  </li>
	<li>
	[<font color=magenta>issued</font>]&nbsp
	<strong>Method and apparatus for providing information, and computer readable storage medium</strong>
	<br><i><u>S Yoon</u>, M Lee, M Koo, J Nam</i>
	<br>KR 10-1773167, Aug. 24, 2017 &nbsp
    <p>
  </li>
  <li>
	[<font color=magenta>issued</font>]
	<strong>Method for recommendation of application, mobile terminal thereof and communication system thereof</strong>
	<br><i>J Nam, M Lee, M Koo, <u>S Yoon</u></i>
	<br>KR 10-1747303, Jun. 8, 2017 &nbsp
    <p>
  </li>
  <li>
	[<font color=magenta>issued</font>]
	<strong>Method and apparatus for fast positioning using global positioning system</strong>
	<br><i><u>S Yoon</u>, S Kim</i>
	<br>KR 10-1564938, Oct. 27, 2015 &nbsp
    <p>
  </li>
  
  <li>
	<strong>Apparatus and method for evaluating sentense by using bidirectional language model</strong>
	<br><i>K Jung, J Shin, <u>S Yoon</u></i>
	<br>KR 1020190165712, Dec. 12, 2019
    <p>
  </li>
  
  <li>
	<strong>Device and method for analyzing user emotion</strong>
	<br><i>E Rhim, J Kim, J Nam, <u>S Yoon</u>, K Park, J Park, M Cha</i>
	<br>KR 1020190165712, May. 13, 2016
    <p>
  </li>
  
<!--
  <li>
	<strong>Method and apparatus for changing personal information</strong>
	<br><i><u>S Yoon</u>, S Lee, O Kwon, M Kim, H Oh, Y Won, S Cha</i>
	<br>KR 1020130122222, Oct. 14, 2013
    <p>
  </li>
  <li>
	<strong>Apparatus and method for setting manner mode in portable terminal</strong>
	<br><i>J Nam, M Lee, M Koo, <u>S Yoon</u></i>
	<br>KR 1020110113927, Nov. 3, 2011
    <p>
  </li>
-->

</font>
</ol>

<!-- [<a href="{{ site.baseurl }}/assets/patent/patent_full.html">see all</a>] -->
